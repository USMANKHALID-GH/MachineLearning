{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPa5m2H3t3/Y9+ToQ3n6OJ/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/USMANKHALID-GH/MachineLearning/blob/master/Self_supervised_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pws9ZIITSs3o"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data loading"
      ],
      "metadata": {
        "id": "W9v635yBS6zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test)=tf.keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "OcbPvxp6S5yw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"y_train before categorical : {y_train.shape}\"); print(f\"y_test before categorical: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqJjTZwZUpgZ",
        "outputId": "5cad321a-dd13-4b75-b6e6-de9b21a403ed"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train before categorical : (50000, 1)\n",
            "y_test before categorical: (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=x_train/255\n",
        "x_test=x_test/255"
      ],
      "metadata": {
        "id": "M6bRNNeKTN9q"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test=tf.keras.utils.to_categorical(y_test)\n",
        "y_train=tf.keras.utils.to_categorical(y_train)"
      ],
      "metadata": {
        "id": "0StjZ1kUTOBO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-380DK1mTtas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdnpA_eeTiyo",
        "outputId": "1317855f-1caa-4c8c-fcf0-4a4cfe5ba816"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"y_train after categorical : {y_train.shape}\"); print(f\"y_test after categorical: {y_test.shape}\")\n",
        "print(f\"x_train  : {x_train.shape}\"); print(f\"x_test : {x_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3_KvrjBTsOP",
        "outputId": "011857a8-8290-46be-853a-1c908e8ae703"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train after categorical : (50000, 10)\n",
            "y_test after categorical: (10000, 10)\n",
            "x_train  : (50000, 32, 32, 3)\n",
            "x_test : (10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating constrative input and output for our data"
      ],
      "metadata": {
        "id": "omPl9dlCV4JH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fun_augment=tf.keras.layers.RandomRotation(factor=0.2)\n",
        "x_train_augmented=fun_augment(x_train)\n",
        "print(f\"augmented dataset shape: {x_train_augmented.shape}\")\n",
        "#  concat the original dataset and augmented dataset for the pretext work\n",
        "x_train_pretext=tf.concat([x_train,x_train_augmented],axis=0)\n",
        "\n",
        "print(f\"combined dataset for pretext shape: {x_train_pretext.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRBll7OBTsSX",
        "outputId": "507f42d4-be87-46e8-88d5-e68b126eefa3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "augmented dataset shape: (50000, 32, 32, 3)\n",
            "combined dataset for pretext shape: (100000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output\n",
        "print(f\" x_ train first layers : {x_train.shape[0]}\")\n",
        "print(f\" x_ train first layers : {x_train_augmented.shape[0]}\")\n",
        "data_output_pretext_positive=tf.ones((x_train.shape[0],1))\n",
        "data_output_pretext_negative=tf.zeros((x_train_augmented.shape[0],1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vNd63YTXSD6",
        "outputId": "cdd9c7c3-37c6-4c7e-de15-fc94107d4e87"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " x_ train first layers : 50000\n",
            " x_ train first layers : 50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_pretext_output=tf.concat([data_output_pretext_positive,data_output_pretext_negative],axis=0)\n",
        "print(f\"pretext dataset output: {x_train_pretext_output.shape}\")\n",
        "print(f\"dataset example: {x_train_pretext_output[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLUQikvjYCn8",
        "outputId": "f2c4cfe8-3d9e-47d7-d0b4-514da07b32ef"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pretext dataset output: (100000, 1)\n",
            "dataset example: [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jBCPz72uZ2C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YwKzRxTkZ2Kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_pretext_output=tf.keras.utils.to_categorical(x_train_pretext_output)\n",
        "print(f\"pretext dataset output: {x_train_pretext_output.shape}\")\n",
        "print(f\"dataset example: {x_train_pretext_output[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkE3N92kZEeP",
        "outputId": "3d3601a4-6569-41e6-f7f1-f4aee01ad379"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pretext dataset output: (100000, 2, 2)\n",
            "dataset example: [[[1. 0.]\n",
            "  [0. 1.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [0. 1.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [0. 1.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [0. 1.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [0. 1.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [0. 1.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [0. 1.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [0. 1.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [0. 1.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [0. 1.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# limit the number of labeled data to 1000\n",
        "num_labeled=1000\n",
        "index_train=tf.experimental.numpy.random.randint(0,x_train.shape[0],num_labeled)\n",
        "\n",
        "x_train_labeled=x_train[index_train,:,:,:]\n",
        "y_train_labeled=y_train[index_train,:]"
      ],
      "metadata": {
        "id": "a9HGLu--Z22d"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "x_train_fully=copy.deepcopy(x_train_labeled)\n",
        "y_train_fully=copy.deepcopy(y_train_labeled)\n",
        "\n",
        "x_train_downstream=copy.deepcopy(x_train_labeled)\n",
        "y_train_downstream=copy.deepcopy(y_train_labeled)\n",
        "\n"
      ],
      "metadata": {
        "id": "oqTYMetEZ3AH"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model creation\n",
        "\n",
        "# Assuming x_train has the shape (batch_size, height, width, channels)\n",
        "input_layer = tf.keras.Input(shape=(x_train.shape[1], x_train.shape[2], x_train.shape[3]))\n",
        "reshaping=tf.keras.layers.Lambda(lambda x: tf.image.resize_with_pad(\n",
        "    x,160,160, method=tf.image.ResizeMethod.BILINEAR))(input_layer)\n",
        "\n",
        "model_DenseNet121 = tf.keras.applications.DenseNet121(include_top  = False,\n",
        "                                                      weights      = None,\n",
        "                                                      input_shape  = (160,160,3),\n",
        "                                                      input_tensor = reshaping,\n",
        "                                                      pooling      = 'max')\n",
        "model_base_fully =  tf.keras.models.clone_model(model_DenseNet121)\n",
        "model_base_pretext =  tf.keras.models.clone_model(model_DenseNet121)\n",
        "\n",
        "\n",
        "model_base_fully.set_weights(model_DenseNet121.get_weights())\n",
        "model_base_pretext.set_weights(model_DenseNet121.get_weights())\n",
        "\n",
        "# normalization layers\n",
        "layer_batchnorm_fsp = tf.keras.layers.BatchNormalization()\n",
        "layer_batchnorm_prx = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "\n",
        "# output layers\n",
        "print(f\"y_train_fully: {y_train_fully.shape[-1]}\")\n",
        "output_layer_fully = tf.keras.layers.Dense(y_train_fully.shape[-1],\n",
        "                                    activation = 'softmax')\n",
        "print(f\"x_train_pretext_output: {x_train_pretext_output.shape[-1]}\")\n",
        "output_layer_pretext = tf.keras.layers.Dense(x_train_pretext_output.shape[-1],\n",
        "                                    activation = 'softmax')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTw1DpZdb7aU",
        "outputId": "39dc4051-007a-40d9-bd8e-b403b2fa9f3c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train_fully: 10\n",
            "x_train_pretext_output: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_fsp   = tf.keras.models.Sequential([model_base_fully,\n",
        "                                          layer_batchnorm_fsp,\n",
        "                                          output_layer_fully])\n",
        "\n",
        "model_prx   = tf.keras.models.Sequential([model_base_pretext,\n",
        "                                          layer_batchnorm_prx,\n",
        "                                          output_layer_pretext])\n",
        "\n",
        "model_fsp.compile(optimizer = tf.keras.optimizers.Adam(0.001),\n",
        "                  loss      = 'categorical_crossentropy',\n",
        "                  metrics   = ['accuracy'])\n",
        "\n",
        "model_prx.compile(optimizer = tf.keras.optimizers.Adam(0.001),\n",
        "                  loss      = 'categorical_crossentropy',\n",
        "                  metrics   = ['accuracy'])"
      ],
      "metadata": {
        "id": "FoivNr9ohBLN"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Base model | fsp: ', model_fsp.layers[0].layers[10].weights[0][0][0][0][:5])\n",
        "print('Base model | prx: ', model_prx.layers[0].layers[10].weights[0][0][0][0][:5])\n",
        "\n",
        "print('Batch normalizaiton layer | fsp: ', model_fsp.layers[1].weights[:2])\n",
        "print('Batch normalizaiton layer | prx: ', model_prx.layers[1].weights[:2])\n",
        "\n",
        "'''\n",
        "Let's keep model_fsp last layer's initial parameters for later use.\n",
        "'''\n",
        "layerou_fsp_initial_parameters = copy.deepcopy(model_fsp.layers[2].weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "393IzQAyhulY",
        "outputId": "6586b941-d131-44a5-a400-64acc9d584d6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base model | fsp:  tf.Tensor([-0.02986425  0.12511803 -0.17394464 -0.06576502 -0.05012904], shape=(5,), dtype=float32)\n",
            "Base model | prx:  tf.Tensor([-0.02986425  0.12511803 -0.17394464 -0.06576502 -0.05012904], shape=(5,), dtype=float32)\n",
            "Batch normalizaiton layer | fsp:  [<tf.Variable 'batch_normalization_2/gamma:0' shape=(1024,) dtype=float32, numpy=array([1., 1., 1., ..., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_2/beta:0' shape=(1024,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>]\n",
            "Batch normalizaiton layer | prx:  [<tf.Variable 'batch_normalization_3/gamma:0' shape=(1024,) dtype=float32, numpy=array([1., 1., 1., ..., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_3/beta:0' shape=(1024,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"shape: {x_train_fully.shape}\")\n",
        "print(f\"shape: {y_train_fully.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZm5TFovjLnp",
        "outputId": "5aa2c587-3156-4348-8eba-e4eba5c5279b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (1000, 32, 32, 3)\n",
            "shape: (1000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_fsp = model_fsp.fit(x_train_fully,\n",
        "                            y_train_fully,\n",
        "                            epochs           = 5,\n",
        "                            batch_size       = 32,\n",
        "                            verbose          = 1,\n",
        "                            shuffle          = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nio33t5CiXYk",
        "outputId": "047036af-993a-41e2-8bf9-36aae9716c27"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "32/32 [==============================] - 97s 421ms/step - loss: 2.3937 - accuracy: 0.2050\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 7s 215ms/step - loss: 1.8737 - accuracy: 0.3460\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 6s 193ms/step - loss: 1.6045 - accuracy: 0.4450\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 6s 197ms/step - loss: 1.3863 - accuracy: 0.5060\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 6s 191ms/step - loss: 1.1680 - accuracy: 0.6050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor              = 'val_loss',\n",
        "                                            patience             = 2,\n",
        "                                            restore_best_weights = True)\n",
        "\n",
        "history_prx = model_prx.fit( x_train_pretext,\n",
        "                            x_train_pretext_output,\n",
        "                            epochs           = 5,\n",
        "                            batch_size       = 32,\n",
        "                            verbose          = 1,\n",
        "                            shuffle          = True,\n",
        "                            validation_split = 0.05,\n",
        "                            callbacks        = [callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8itJLPqjskq",
        "outputId": "7abbf8cb-191d-48d3-fa08-15b008a2fec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2969/2969 [==============================] - 642s 198ms/step - loss: 0.0000e+00 - accuracy: 0.5263 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/5\n",
            "2969/2969 [==============================] - 578s 195ms/step - loss: 0.0000e+00 - accuracy: 0.5263 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/5\n",
            " 595/2969 [=====>........................] - ETA: 7:37 - loss: 0.0000e+00 - accuracy: 0.5206"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Control if model_fsp has similar hyper-parameters as model_prx\n",
        "'''\n",
        "\n",
        "print('Base model | fsp: ', model_fsp.layers[0].layers[10].weights[0][0][0][0][:5])\n",
        "print('Base model | prx: ', model_prx.layers[0].layers[10].weights[0][0][0][0][:5])\n",
        "\n",
        "print('Batch normalizaiton layer | fsp: ', model_fsp.layers[1].weights[:2])\n",
        "print('Batch normalizaiton layer | prx: ', model_prx.layers[1].weights[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRbeIbCKiXb8",
        "outputId": "d981baed-1025-4a8b-ec03-9e1b81cb23ba"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base model | fsp:  tf.Tensor([-0.03393763  0.13035484 -0.18123257 -0.06270994 -0.05973897], shape=(5,), dtype=float32)\n",
            "Base model | prx:  tf.Tensor([ 0.00906945  0.14211026 -0.16112804  0.03204448 -0.0425082 ], shape=(5,), dtype=float32)\n",
            "Batch normalizaiton layer | fsp:  [<tf.Variable 'batch_normalization_2/gamma:0' shape=(1024,) dtype=float32, numpy=\n",
            "array([0.997861  , 0.99324596, 0.9894802 , ..., 0.9934368 , 0.9850776 ,\n",
            "       1.0035125 ], dtype=float32)>, <tf.Variable 'batch_normalization_2/beta:0' shape=(1024,) dtype=float32, numpy=\n",
            "array([-0.00407274, -0.00872419, -0.00772908, ..., -0.01838654,\n",
            "        0.0235607 , -0.0185999 ], dtype=float32)>]\n",
            "Batch normalizaiton layer | prx:  [<tf.Variable 'batch_normalization_3/gamma:0' shape=(1024,) dtype=float32, numpy=\n",
            "array([5.4645495, 5.4618316, 5.4398956, ..., 5.4236836, 5.4388657,\n",
            "       5.4175067], dtype=float32)>, <tf.Variable 'batch_normalization_3/beta:0' shape=(1024,) dtype=float32, numpy=\n",
            "array([ 4.323962 ,  4.298325 , -4.2573156, ...,  4.290437 ,  4.298639 ,\n",
            "        4.259176 ], dtype=float32)>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kPBwcylpkMyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DownStreamTask"
      ],
      "metadata": {
        "id": "ZUn0vKdlrmfJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DOWNStream Task"
      ],
      "metadata": {
        "id": "ypspbet2r3sE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DaDlBvg7r3pQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layerou_dwm = tf.keras.layers.Dense(y_train_downstream.shape[-1],\n",
        "                                    activation = 'softmax')"
      ],
      "metadata": {
        "id": "ifuwxFCxrl9g"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_base_pretext.trainable      = False\n",
        "layer_batchnorm_prx.trainable = False\n",
        "\n",
        "model_dwm   = tf.keras.models.Sequential([model_base_pretext,\n",
        "                                          layer_batchnorm_prx,\n",
        "                                          layerou_dwm])"
      ],
      "metadata": {
        "id": "7VD51s1DsSI5"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dwm.layers[2].set_weights(layerou_fsp_initial_parameters)\n",
        "\n",
        "\n",
        "model_dwm.compile(optimizer = tf.keras.optimizers.Adam(0.001),\n",
        "                  loss      = 'categorical_crossentropy',\n",
        "                  metrics   = ['accuracy'])"
      ],
      "metadata": {
        "id": "m1eP_YrwsoMw"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_base_pretext.trainable      = False\n",
        "layer_batchnorm_prx.trainable = False\n",
        "\n",
        "model_dwm   = tf.keras.models.Sequential([model_base_pretext,\n",
        "                                          layer_batchnorm_prx,\n",
        "                                          layerou_dwm])\n",
        "model_dwm.summary()\n",
        "\n",
        "history_dwm = model_dwm.fit(x_train_downstream ,\n",
        "                             y_train_downstream,\n",
        "                            epochs           = 2,\n",
        "                            batch_size       = 35,\n",
        "                            verbose          = 1,\n",
        "                            shuffle          = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWEKVKrTsyTP",
        "outputId": "264122b0-15a1-469b-e023-8409a6b1e008"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet121 (Functional)    (None, 1024)              7037504   \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 1024)              4096      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7051850 (26.90 MB)\n",
            "Trainable params: 10250 (40.04 KB)\n",
            "Non-trainable params: 7041600 (26.86 MB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "29/29 [==============================] - 15s 168ms/step - loss: 3.2764 - accuracy: 0.1130\n",
            "Epoch 2/2\n",
            "29/29 [==============================] - 2s 57ms/step - loss: 2.5585 - accuracy: 0.1170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_base_pretext.trainable      = True\n",
        "layer_batchnorm_prx.trainable = True\n",
        "\n",
        "model_dwm   = tf.keras.models.Sequential([model_base_pretext,\n",
        "                                          layer_batchnorm_prx,\n",
        "                                          layerou_dwm])\n",
        "model_dwm.summary()\n",
        "\n",
        "history_dwm = model_dwm.fit(x_train_downstream ,\n",
        "                             y_train_downstream,\n",
        "                            epochs           = 2,\n",
        "                            batch_size       = 35,\n",
        "                            verbose          = 1,\n",
        "                            shuffle          = True)"
      ],
      "metadata": {
        "id": "Pc4Y1MW2tXKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, acc_te_fsp = model_fsp.evaluate(x_test,\n",
        "                                    y_test,\n",
        "                                   batch_size = 128)\n",
        "\n",
        "_, acc_te_dwm = model_dwm.evaluate(x_test,\n",
        "                                   y_test,\n",
        "                                   batch_size = 128)\n",
        "\n",
        "print('Accuracy of fsp: {:05.2f}%'.format(acc_te_fsp*100))\n",
        "print('Accuracy of dwm: {:05.2f}%'.format(acc_te_dwm*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4WNnAg1tXSk",
        "outputId": "2c0640fd-63c1-4c56-de8b-289ee9ff7a0e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 26s 217ms/step - loss: 3.2243 - accuracy: 0.1455\n",
            "79/79 [==============================] - 17s 179ms/step - loss: 2.7575 - accuracy: 0.1320\n",
            "Accuracy of fsp: 14.55%\n",
            "Accuracy of dwm: 13.20%\n"
          ]
        }
      ]
    }
  ]
}